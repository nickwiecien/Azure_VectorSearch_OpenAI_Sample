{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a33c7cd2-a999-4970-a07b-7ddc0264fce0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Azure OpenAI - Retrieval Augmented Generation Sample\n",
    "Sample notebook showcasing how to create an vector search index in Azure Cognitive Search (using PDF documents sourced from an Azure Blob Storage account) and how to ask questions of that data using LLMs through the Azure OpenAI Service. Note: This sample has been assembled to demonstrate the core steps in the workflow listed below - there are significant optimizations that can be made to afford increased parallelism during document creation/indexing. It has been adapted from the scripts provided as part of this [Microsoft Cognitive Search + Azure OpenAI accelerator](https://github.com/Azure-Samples/azure-search-openai-demo/blob/main/scripts/prepdocs.py).\n",
    "\n",
    "#### Workflow\n",
    "- Mount storage and list all files\n",
    "- Create Vector Search Index (Az Cog Search)\n",
    "- Iterate over all files\n",
    "- Split into individual pages\n",
    "- Save pages to target container\n",
    "- Get text and tables\n",
    "- Create documents for cog search (embeddings)\n",
    "- Add documents to index\n",
    "- Ask questions of data using LLMs in Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e08c8f0e-c422-47d3-abea-9a6ad4370f6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Import required packages\n",
    "\n",
    "Note: The following python packages need to be installed in your cluster environment and can be sourced from PyPI.\n",
    "- azure-ai-formrecognizer\n",
    "- azure-identity\n",
    "- azure-search-documents==11.4.0a20230509004 (Index URL: https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/)\n",
    "- azure-storage-blob\n",
    "- openai\n",
    "- pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents==11.4.0a20230509004 --extra-index-url https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/\n",
    "! pip install azure-ai-formrecognizer azure-identity azure-storage-blob openai pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bff4a730-03cb-4761-987d-33660acd83d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import html\n",
    "import base64\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "import openai\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import AzureDeveloperCliCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import *\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "from IPython.display import display, HTML \n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import Vector \n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration, \n",
    ")\n",
    "from IPython.display import display, HTML  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0df3441b-8a4a-4129-a960-1087548ad640",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set/retrieve environment variables\n",
    "\n",
    "The following environment variables are expected. You could load these manually or from a standalone .env file.\n",
    "\n",
    "| Key                       | Value                                                        |  \n",
    "| ------------------------- | ------------------------------------------------------------ |  \n",
    "| storage_account_name      | The name of your Azure Storage account                       |  \n",
    "| docs_container            | The name of the container in your Storage account for documents |  \n",
    "| pages_container           | The name of the container in your Storage account for pages  |  \n",
    "| storage_account_key       | The access key of your Azure Storage account                 |  \n",
    "| cog_search_endpoint       | The endpoint for your Azure Cognitive Search service         |  \n",
    "| cog_search_key            | The key for your Azure Cognitive Search service              |  \n",
    "| cog_search_index_name     | The name of the index in your Azure Cognitive Search service |  \n",
    "| afr_endpoint              | The endpoint for your Azure Form Recognizer service          |  \n",
    "| afr_key                   | The key for your Azure Form Recognizer service               |  \n",
    "| aoai_key                  | The key for your Azure OpenAI service                        |  \n",
    "| aoai_endpoint             | The endpoint for your Azure OpenAI service                   |  \n",
    "| aoai_embeddings_model     | The model used for embeddings in your Azure OpenAI service (recommend `text-embedding-ada-002`)   |  \n",
    "| aoai_chat_model           | The model used for chat in your Azure OpenAI service (recommend `gpt-35-turbo-16k`)        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40400fe7-bee7-47e8-a379-f915505b758d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "storage_account_name = os.getenv(\"STORAGE_ACCOUNT_NAME\")\n",
    "docs_container = os.getenv(\"DOCS_CONTAINER\")\n",
    "pages_container = os.getenv(\"PAGES_CONTAINER\")\n",
    "storage_account_key = os.getenv(\"STORAGE_ACCOUNT_KEY\")\n",
    "\n",
    "cog_search_endpoint = os.getenv(\"COG_SEARCH_ENDPOINT\")\n",
    "cog_search_key = os.getenv(\"COG_SEARCH_KEY\")\n",
    "cog_search_index_name = os.getenv(\"COG_SEARCH_INDEX_NAME\")\n",
    "\n",
    "afr_endpoint = os.getenv(\"AFR_ENDPOINT\")\n",
    "afr_key = os.getenv(\"AFR_KEY\")\n",
    "\n",
    "aoai_key = os.getenv(\"AOAI_KEY\")\n",
    "aoai_endpoint = os.getenv(\"AOAI_ENDPOINT\")\n",
    "aoai_embeddings_model = os.getenv(\"AOAI_EMBEDDINGS_MODEL\")\n",
    "aoai_chat_model = os.getenv(\"AOAI_CHAT_MODEL\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = aoai_endpoint\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = aoai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f6dc7ff-bf9b-4b9e-97ee-c6227396c106",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Download local copy of all files in Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eef2a6a-1162-44dd-9dcf-260288c61de0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make a local directory for docs and pages\n",
    "os.makedirs(docs_container, exist_ok=True)\n",
    "os.makedirs(pages_container, exist_ok=True)\n",
    "\n",
    "# Download all docs from the docs container\n",
    "blob_service_client = BlobServiceClient(account_url=f\"https://{storage_account_name}.blob.core.windows.net\", credential=storage_account_key)\n",
    "container_client = blob_service_client.get_container_client(docs_container)\n",
    "blob_list = container_client.list_blobs()\n",
    "for blob in blob_list:\n",
    "    blob_client = blob_service_client.get_blob_client(container=docs_container, blob=blob.name)\n",
    "    with open(os.path.join(docs_container, blob.name), \"wb\") as my_blob:\n",
    "        blob_data = blob_client.download_blob()\n",
    "        blob_data.readinto(my_blob)\n",
    "\n",
    "# Get a list of all the PDF files in the docs container\n",
    "files_list = [x for x in os.scandir(docs_container)]\n",
    "\n",
    "# Filter to only PDF files\n",
    "files_list = [x.name for x in files_list if x.name.lower().endswith('pdf')]\n",
    "\n",
    "# Print the name of each file in the docs container\n",
    "for file in files_list:\n",
    "    print(file)\n",
    "\n",
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31d923f4-07a2-4273-ba6e-b8b3ba6208bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Vector Search Index (Az Cog Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad4b972b-22cc-4c10-acb3-b4206c233f62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_vector_index(endpoint, key, index_name):\n",
    "    \"\"\"\n",
    "    Creates a search index with vector search enabled.\n",
    "\n",
    "    Args:\n",
    "    endpoint (str): The endpoint of the Azure Cognitive Search service.\n",
    "    key (str): The admin key of the Azure Cognitive Search service.\n",
    "    index_name (str): The name of the search index to create.\n",
    "\n",
    "    Returns:\n",
    "    The result of the create_or_update_index operation.\n",
    "    \"\"\"\n",
    "    # Create a SearchIndexClient object\n",
    "    credential = AzureKeyCredential(key)\n",
    "    client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "\n",
    "    # Define the fields for the index\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SimpleField(name=\"page_number\", type=SearchFieldDataType.Int32, filterable=True),\n",
    "        SimpleField(name=\"file_name\", type=SearchFieldDataType.String, filterable=True),\n",
    "        SimpleField(name=\"source_document\", type=SearchFieldDataType.String, filterable=True),\n",
    "        SearchField(name=\"content_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, dimensions=1536, vector_search_configuration=\"vector-config\"),\n",
    "        ]\n",
    "    \n",
    "    vector_search = VectorSearch(\n",
    "        algorithm_configurations=[\n",
    "            VectorSearchAlgorithmConfiguration(\n",
    "                name=\"vector-config\",\n",
    "                kind=\"hnsw\",\n",
    "                hnsw_parameters={\n",
    "                    \"m\": 4,\n",
    "                    \"efConstruction\": 400,\n",
    "                    \"efSearch\": 1000,\n",
    "                    \"metric\": \"cosine\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the search index\n",
    "    index = SearchIndex(name=index_name, fields=fields,\n",
    "                        vector_search=vector_search)\n",
    "    result = client.create_or_update_index(index)\n",
    "\n",
    "    # Return the result\n",
    "    return result\n",
    "\n",
    "try:\n",
    "    # Create the vector search index\n",
    "    create_vector_index(cog_search_endpoint, cog_search_key, cog_search_index_name)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac0d1cd8-f720-4acd-9e9a-c22db32c8779",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Iterate over all files, split into individual pages, and save to target container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa403386-d8c1-4bfa-bce8-1176d11d4c69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def blob_name_from_file_page(filename, page = 0):\n",
    "    \"\"\"\n",
    "    Returns the name of the blob for a given file and page number.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The name of the file.\n",
    "    page (int): The page number.\n",
    "\n",
    "    Returns:\n",
    "    str: The name of the blob.\n",
    "    \"\"\"\n",
    "    if os.path.splitext(filename)[1].lower() == \".pdf\":\n",
    "        return os.path.splitext(os.path.basename(filename))[0] + f\"-{page}\" + \".pdf\"\n",
    "    else:\n",
    "        return os.path.basename(filename)\n",
    "\n",
    "def upload_blobs(filepath, filename):\n",
    "    \"\"\"\n",
    "    Uploads blobs to Azure Blob Storage.\n",
    "\n",
    "    Parameters:\n",
    "    filepath (str): The path to the file.\n",
    "    filename (str): The name of the file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of saved pages.\n",
    "    \"\"\"\n",
    "    saved_pages = []\n",
    "\n",
    "    # if file is PDF split into pages and upload each page as a separate blob\n",
    "    if os.path.splitext(filename)[1].lower() == \".pdf\":\n",
    "        reader = PdfReader(filepath)\n",
    "        pages = reader.pages\n",
    "        for i in range(len(pages)):\n",
    "            blob_name = blob_name_from_file_page(filename, i)\n",
    "            print(f\"\\tUploading blob for page {i} -> {blob_name}\")\n",
    "            page_path = filepath.replace(filename, blob_name).replace('docs/', 'pages/')\n",
    "            f = page_path\n",
    "            writer = PdfWriter()\n",
    "            writer.add_page(pages[i])\n",
    "            writer.write(f)\n",
    "            saved_pages.append(page_path)\n",
    "        return saved_pages\n",
    "\n",
    "saved_pages = []\n",
    "\n",
    "for file in files_list:\n",
    "    saved_pages = saved_pages + upload_blobs(f\"docs/{file}\", file)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d235fbd9-5c91-43fc-96bf-82907c86ec8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "saved_pages = saved_pages[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1d46c9a-ca74-4a21-8076-896948842383",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Extract text/tables from all pages using Azure Form Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6af5a56-a98e-4a45-bf84-5c29b828c7b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analyze_document_with_afr(filename, afr_endpoint, afr_key, actual_page_num, source_filename):\n",
    "    \"\"\"\n",
    "    Analyzes a document using Azure Form Recognizer and extracts text and tables from it.\n",
    "\n",
    "    Args:\n",
    "    - filename (str): The path to the file to be analyzed.\n",
    "    - afr_endpoint (str): The endpoint of the Azure Form Recognizer service.\n",
    "    - afr_key (str): The API key for the Azure Form Recognizer service.\n",
    "    - actual_page_num (int): The actual page number of the page being analyzed.\n",
    "    - source_filename (str): The name of the source file.\n",
    "\n",
    "    Returns:\n",
    "    - page_map (list): A list of tuples, where each tuple contains the actual page number, the extracted text and tables,\n",
    "    the name of the file, and the name of the source file.\n",
    "    \"\"\"\n",
    "    print(f\"\\tExtracting text and tables from {filename}\")\n",
    "    offset = 0\n",
    "    page_map = []\n",
    "    afr_client = DocumentAnalysisClient(endpoint=afr_endpoint, credential=AzureKeyCredential(afr_key))\n",
    "    with open(filename, 'rb') as f:\n",
    "        poller = afr_client.begin_analyze_document(\"prebuilt-layout\", document=f)\n",
    "    form_recognizer_results = poller.result()\n",
    "    for page_num, page in enumerate(form_recognizer_results.pages):\n",
    "            tables_on_page = [table for table in form_recognizer_results.tables if table.bounding_regions[0].page_number == page_num + 1]\n",
    "\n",
    "            # mark all positions of the table spans in the page\n",
    "            page_offset = page.spans[0].offset\n",
    "            page_length = page.spans[0].length\n",
    "            table_chars = [-1]*page_length\n",
    "            for table_id, table in enumerate(tables_on_page):\n",
    "                for span in table.spans:\n",
    "                    # replace all table spans with \"table_id\" in table_chars array\n",
    "                    for i in range(span.length):\n",
    "                        idx = span.offset - page_offset + i\n",
    "                        if idx >=0 and idx < page_length:\n",
    "                            table_chars[idx] = table_id\n",
    "\n",
    "            # build page text by replacing charcters in table spans with table html\n",
    "            page_text = \"\"\n",
    "            added_tables = set()\n",
    "            for idx, table_id in enumerate(table_chars):\n",
    "                if table_id == -1:\n",
    "                    page_text += form_recognizer_results.content[page_offset + idx]\n",
    "                elif not table_id in added_tables:\n",
    "                    page_text += table_to_html(tables_on_page[table_id])\n",
    "                    added_tables.add(table_id)\n",
    "\n",
    "            page_text += \" \"\n",
    "            page_map.append((actual_page_num, page_text, filename.replace('/dbfs/mnt/pages/', ''), source_filename))\n",
    "            offset += len(page_text)\n",
    "\n",
    "    return page_map\n",
    "\n",
    "def table_to_html(table):\n",
    "    \"\"\"\n",
    "    Converts a table object to an HTML table.\n",
    "\n",
    "    Args:\n",
    "    - table (Table): The table object to be converted.\n",
    "\n",
    "    Returns:\n",
    "    - table_html (str): The HTML representation of the table.\n",
    "    \"\"\"\n",
    "    table_html = \"<table>\"\n",
    "    rows = [sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index) for i in range(table.row_count)]\n",
    "    for row_cells in rows:\n",
    "        table_html += \"<tr>\"\n",
    "        for cell in row_cells:\n",
    "            tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "            cell_spans = \"\"\n",
    "            if cell.column_span > 1: cell_spans += f\" colSpan={cell.column_span}\"\n",
    "            if cell.row_span > 1: cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "            table_html += f\"<{tag}{cell_spans}>{html.escape(cell.content)}</{tag}>\"\n",
    "        table_html +=\"</tr>\"\n",
    "    table_html += \"</table>\"\n",
    "    return table_html\n",
    "\n",
    "# Regular expression pattern for extracting source document name, and page number for each individually saved page\n",
    "pattern = r\"pages/(\\w+)-(\\d+).pdf\"\n",
    "\n",
    "page_maps = []\n",
    "\n",
    "# Iterate over all saved pages\n",
    "for file in saved_pages:\n",
    "    # Extract source filename and page number\n",
    "    match = re.search(pattern, file)\n",
    "    if match:\n",
    "        filename = match.group(1) + '.pdf'\n",
    "        page_number = match.group(2)\n",
    "        # Extract text and tables from page using Azure Form Recognizer and append to a list\n",
    "        page_maps += analyze_document_with_afr(file, afr_endpoint, afr_key, page_number, filename)\n",
    "\n",
    "print(page_maps[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50be11ef-8a79-4fbc-9369-7022a3e27bb4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create & add documents to Azure Cognitive Search with Azure OpenAI-generated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "024ae625-b288-4f82-8524-bcde7d465fed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(text, embeddings_model):\n",
    "    \"\"\"\n",
    "    Generates embeddings for the given text using the specified embeddings model.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to generate embeddings for.\n",
    "    embeddings_model (str): The name of the embeddings model to use.\n",
    "\n",
    "    Returns:\n",
    "    The embeddings generated for the given text.\n",
    "    \"\"\"\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=embeddings_model)\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "def insert_document_vector(endpoint, key, index_name, document):\n",
    "    \"\"\"\n",
    "    Inserts a document vector into the specified search index.\n",
    "\n",
    "    Args:\n",
    "    endpoint (str): The endpoint of the search service.\n",
    "    key (str): The API key for the search service.\n",
    "    index_name (str): The name of the search index.\n",
    "    document (dict): The document vector to insert.\n",
    "\n",
    "    Returns:\n",
    "    The result of the document upload operation.\n",
    "    \"\"\"\n",
    "    # Create a SearchClient object\n",
    "    credential = AzureKeyCredential(key)\n",
    "    client = SearchClient(endpoint=endpoint, index_name=index_name, credential=credential)\n",
    "\n",
    "    # Call the upload_documents method of the client with a list of documents\n",
    "    result = client.upload_documents(documents=[document])\n",
    "\n",
    "    # Return the result\n",
    "    return result\n",
    "\n",
    "def hash_string(input_string):  \n",
    "    \"\"\"\n",
    "    Hashes the given string using SHA-256.\n",
    "\n",
    "    Args:\n",
    "    input_string (str): The string to hash.\n",
    "\n",
    "    Returns:\n",
    "    The SHA-256 hash of the input string.\n",
    "    \"\"\"\n",
    "    sha_signature = hashlib.sha256(input_string.encode()).hexdigest()  \n",
    "    return sha_signature  \n",
    "\n",
    "def create_and_insert_document(afr_extraction, cog_search_endpoint, cog_search_key, cog_search_index_name, aoai_embeddings_model):\n",
    "    \"\"\"\n",
    "    Creates a document vector for the given AFR extraction and inserts it into the specified search index.\n",
    "\n",
    "    Args:\n",
    "    afr_extraction (tuple): The AFR extraction to create a document vector for.\n",
    "    cog_search_endpoint (str): The endpoint of the Cognitive Search service.\n",
    "    cog_search_key (str): The API key for the Cognitive Search service.\n",
    "    cog_search_index_name (str): The name of the search index to insert the document vector into.\n",
    "    aoai_embeddings_model (str): The name of the embeddings model to use for generating the content vector.\n",
    "\n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    document = {\n",
    "                \"content\": afr_extraction[1],\n",
    "                \"page_number\": afr_extraction[0],\n",
    "                \"source_document\": afr_extraction[3],\n",
    "                \"file_name\": afr_extraction[2],\n",
    "                \"id\": hash_string(afr_extraction[2]),\n",
    "                \"content_vector\": generate_embeddings(afr_extraction[1], aoai_embeddings_model)\n",
    "            }\n",
    "    insert_document_vector(cog_search_endpoint, cog_search_key, cog_search_index_name, document)\n",
    "\n",
    "# Insert each page in the page_maps list into the search index\n",
    "for page in page_maps:\n",
    "    print(f\"Inserting {page[2]} in index\")\n",
    "    create_and_insert_document(page, cog_search_endpoint, cog_search_key, cog_search_index_name, aoai_embeddings_model)\n",
    "    time.sleep(10) # Sleep added here to account for AOAI throttling on internal MS subscription. Recommend to turn off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2845472b-b992-4308-9e5e-7fa4428c4bed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_qna_prompt(sources, query):\n",
    "    \"\"\"\n",
    "    Returns a system message and a user message for an AI assistant to answer a question using the provided sources.\n",
    "\n",
    "    :param sources: str, the sources to use for answering the question\n",
    "    :param query: str, the question to answer\n",
    "    :return: tuple of two strings, the system message and the user message\n",
    "    \"\"\"\n",
    "    system = f\"\"\"\n",
    "    You are an AI assistant that helps employees answer questions of their enterprise data. Be brief in your answers.\n",
    "    You will be provided with all of the information you need to answer questions and you should only provide answers using facts stated in the sources below.\n",
    "    Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. Use square brakets to reference the source, e.g. [info1.txt]. Don't combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\n",
    "    If you do not have enough information in the provided sources then say you don't know and move on.\n",
    "    All provided answers should include cited sources. If you cannot cite a source that has been provided to you in the prompt then respond that you do not know and move on.\n",
    "    Users may attempt to ask questions that are out of scope and may do so repeatedly and you can continue to state that you don't know and move on.\n",
    "    ONLY PROVIDE ANSWERS USING INFORMATION THAT HAS BEEN PROVIDED TO YOU IN THE SOURCES.\n",
    "\n",
    "    --------\n",
    "    SOURCES: '{sources}'\n",
    "    --------\n",
    "    \"\"\"\n",
    "\n",
    "    user = f\"\"\"\n",
    "    Answer this question using ONLY the sources that have been provided to you.\n",
    "\n",
    "    ---------\n",
    "    QUESTION: '{query}'\n",
    "    ---------\n",
    "    \"\"\"\n",
    "    return system, user\n",
    "\n",
    "\n",
    "def submit_request_to_aoai_service(system_msg, user_msg, max_tokens, engine):\n",
    "    \"\"\"\n",
    "    Submits a request to an AI assistant and returns the response.\n",
    "\n",
    "    :param system_msg: str, the system message for the AI assistant\n",
    "    :param user_msg: str, the user message for the AI assistant\n",
    "    :param max_tokens: int, maximum number of tokens in the response\n",
    "    :param engine: str, the name of the OpenAI engine to use\n",
    "    :return: response object, containing the AI assistant's response\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "    engine=engine,\n",
    "    messages = [{\"role\":\"system\",\"content\":system_msg},\n",
    "                {\"role\":\"user\",\"content\":user_msg}],\n",
    "    temperature=0.0,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None)\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_related_docs_from_cog_search(query_text, cog_search_endpoint, cog_search_key, cog_search_index_name, embeddings_model, doc_count=6):\n",
    "    \"\"\"\n",
    "    Returns a string containing the related documents from Azure Cognitive Search for a given query.\n",
    "\n",
    "    :param query_text: str, the query to search for\n",
    "    :param cog_search_endpoint: str, the endpoint for the Azure Cognitive Search service\n",
    "    :param cog_search_key: str, the API key for the Azure Cognitive Search service\n",
    "    :param cog_search_index_name: str, the name of the index to search in the Azure Cognitive Search service\n",
    "    :param embeddings_model: str, the name of the embeddings model to use\n",
    "    :param doc_count: int, the number of documents to return\n",
    "    :return: str, the related documents from Azure Cognitive Search\n",
    "    \"\"\"\n",
    "    search_client = SearchClient(cog_search_endpoint, cog_search_index_name, AzureKeyCredential(cog_search_key))\n",
    "\n",
    "    results = search_client.search(\n",
    "        search_text=\"\",\n",
    "        vector=Vector(value=generate_embeddings(query_text, aoai_embeddings_model), k=doc_count, fields=\"content_vector\"),\n",
    "        select=[\"page_number\", \"content\", \"source_document\", \"file_name\"]\n",
    "    )\n",
    "\n",
    "    bid_doc_text = ''\n",
    "    for idx, res in enumerate(results):\n",
    "        bid_doc_text += '    ---------  SOURCE_DOCUMENT: ' + res['file_name'] + ' | PAGE NUMBER ' + str(res['page_number']) + ': ' + res['content'] + '\\n\\n\\n'\n",
    "    return bid_doc_text\n",
    "\n",
    "\n",
    "def ask_question_of_your_data(query, cog_search_endpoint, cog_search_key, cog_search_index_name, aoai_embeddings_model):\n",
    "    \"\"\"\n",
    "    Asks a question of an AI assistant using related documents from Azure Cognitive Search and returns the response.\n",
    "\n",
    "    :param query: str, the question to ask the AI assistant\n",
    "    :param cog_search_endpoint: str, the endpoint for the Azure Cognitive Search service\n",
    "    :param cog_search_key: str, the API key for the Azure Cognitive Search service\n",
    "    :param cog_search_index_name: str, the name of the index to search in the Azure Cognitive Search service\n",
    "    :param aoai_embeddings_model: str, the name of the embeddings model to use\n",
    "    :return: str, the response from the AI assistant\n",
    "    \"\"\"\n",
    "    sources = get_related_docs_from_cog_search(query, cog_search_endpoint, cog_search_key, cog_search_index_name, aoai_embeddings_model)\n",
    "    system_msg, user_msg = get_qna_prompt(sources, query)\n",
    "    response = submit_request_to_aoai_service(system_msg, user_msg, 500, aoai_chat_model)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage:\n",
    "user_question = \"What options do I have for fitness reimbursement?\"\n",
    "\n",
    "response = ask_question_of_your_data(user_question, cog_search_endpoint, cog_search_key, cog_search_index_name, aoai_embeddings_model)\n",
    "\n",
    "display(HTML(f\"<h3>Question: <i>{user_question}</i></h3>\"))\n",
    "display(HTML(f\"<h3>Answer: {response}</h3>\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MSFT_Azure_OpenAI_Cog_Search_Sample",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
